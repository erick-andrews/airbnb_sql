{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea0b17bd-9fb8-4a91-ad2d-fe863cf93a30",
   "metadata": {},
   "source": [
    "# Italian AirBnB: A SQL Showcase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5bca0-48e6-4ed4-b1e0-20fe10fd809c",
   "metadata": {},
   "source": [
    "## The Beginning\n",
    "As someone who studied and lived in southern Switzerland for four years, just minutes from the Italian border, and who learned Italian to a C1 level, I have a fond place in my heart for Italy and Italian culture. As a well-traveled person with an insatiable curiousity, I wanted to examine Italian AirBnB rentals for insights I might glean, while learning and showing off my SQL and Python skills.\n",
    "\n",
    "I found a dataset on kaggle at https://www.kaggle.com/datasets/salvatoremarcello/italian-airbnb-dataset. Other AirBnB datasets of interest reside here https://insideairbnb.com/get-the-data/. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611d88c1-7872-4c08-bb91-38d0d089cedb",
   "metadata": {},
   "source": [
    "## Prepping our data for load\n",
    "\n",
    "While the structures of this git repository and associated databases are intended to mimic a potential production setup, certain elements (such as the absence of scheduled ETL) are missing. The focus of this project and associated resources is to showcase SQL competency, and as a consequence, some infrastructural knowledge around OLAP database structure. In our case, the overall structure be as follows:\n",
    "1. A jupyter notebook (this one) cleans our csv\n",
    "2. DDL scripts are run to prep a data mart for loading\n",
    "3. A staging table is loaded from cleaned csv via a bash script\n",
    "4. The staging table is then written to the data mart and erased\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Postgres may not be the ideal OLAP RDBMS, but for this use case it works sufficiently well. It was chosen for many reasons, among them: 1. PostgreSQL is common and PL/pgSQL is a familiar language, 2. Quick deploy with bitnami helm chart for availability even locally, and 3. it integrates with Tableau\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6fb668-0122-47b3-bac4-065c6cdf8018",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a80085d-4048-4cfb-9d07-ff05adebfba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'constants.py', 'cleaning.ipynb', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "# Load in packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Constants import for brevity\n",
    "from constants import *\n",
    "# Setting max display\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "993c074f-fee5-43da-b23b-918c88efeed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load in our dataset.\n",
    "exp = pd.read_csv(\"~/projects/airbnb_sql/op-db/airbnb.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d7064c-0457-488e-a893-334329ad644a",
   "metadata": {},
   "source": [
    "### Some investigation\n",
    "\n",
    "I want to see what I'm working with here, so I look at the cities, how long our hosts have been around, and what dates our scrapings occurred. This is to get a feel for the data. Finally, I look at 10 rows. (Condensed from 100 for clarity + brevity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b90677c-ecbd-40f0-8c6d-a95708be9258",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'exp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Printing our unique values\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39munique(\u001b[43mexp\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(pd\u001b[38;5;241m.\u001b[39munique(exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHost since\u001b[39m\u001b[38;5;124m'\u001b[39m])))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(pd\u001b[38;5;241m.\u001b[39munique(exp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate of scraping\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exp' is not defined"
     ]
    }
   ],
   "source": [
    "# Printing our unique values\n",
    "print(pd.unique(exp['City']))\n",
    "print(len(pd.unique(exp['Host since'])))\n",
    "print(pd.unique(exp['Date of scraping']))\n",
    "# Taking the head\n",
    "exp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09825245-145c-453d-8ce2-d298b692299f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0a792b-a32b-43ed-b612-239413a6a2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4f1611-546e-4cc4-9e88-f47d892698cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pd.unique(exp['Listings id'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2109cd0-49bf-4a2f-8501-47864859ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp[exp[\"City\"] == \"Firenze\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f72cbf-85a9-4d19-b07c-2c45e7c3ad47",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_observations = exp[exp['Listings id'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91e9136-1c74-4796-966a-10d194256b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe50e788-7857-40bc-bb73-7b1576bff730",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_observations[repeated_observations['Listings id'] == 222527]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656d5bc-0dcd-4b4d-951b-2e8a2418f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "\n",
    "def to_wkt(coord):\n",
    "    lat, lon = map(float, coord.split(','))\n",
    "    return Point(lon, lat).wkt  # Note: WKT format is (lon lat)\n",
    "\n",
    "exp['Coordinates'] = exp['Coordinates'].apply(to_wkt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e61717-bed2-41d3-8045-f3940bed2f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "exp = exp.rename(columns=column_mapping)\n",
    "# Select and reorder the columns\n",
    "exp = exp[staging_columns]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a452036-5954-4df4-904f-1c707d4ebe3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp['host_is_superhost'] = exp['host_is_superhost'].map({'Superhost': True, 'Host': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33cbfb-919a-4fe8-af42-3c92128a0a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.to_csv(\"/home/eandrews/projects/de-proj-1/op-db/airbnb_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce38259-15b8-4864-a73b-64442d44bf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.read_csv('/home/eandrews/projects/de-proj-1/op-db/airbnb_clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "airbnb_sql",
   "language": "python",
   "name": "airbnb_sql"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
